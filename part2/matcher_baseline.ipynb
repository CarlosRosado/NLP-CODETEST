{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seedtag codetest: NLP Researcher\n",
    "\n",
    "## Part 3. Message-matcher baseline model\n",
    "This communication contains a message matcher baseline model. Given a query text message and a corpus of historical messages, this matcher model retrieves all historical messages that are similar to the queried one. Your goal is to improve this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from hashlib import md5\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(path, tag):\n",
    "    '''\n",
    "    Creates a data frame for a given class\n",
    "    --------------------------------------\n",
    "    Input:\n",
    "        path (str): path where all classes folders are stored.\n",
    "        tag (str): name of the folder containing class \"tag\".\n",
    "    Output:\n",
    "        df (pd.DataFrame): dataframe with file as index and columns=[text, tag]\n",
    "    '''\n",
    "    list_of_text = []\n",
    "    tag_dir = os.path.join(path, tag)\n",
    "    for file in os.listdir(tag_dir):\n",
    "\n",
    "        with open(os.path.join(tag_dir, file), encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            text = f.read()\n",
    "            list_of_text.append((text, file))\n",
    "            df = pd.DataFrame(list_of_text, columns = ['Text', 'file'])\n",
    "            df = df.set_index('file')\n",
    "    df['tag'] = tag\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_all_dfs(path, tags):\n",
    "    '''\n",
    "    Loops over all classes in path, each in the corresponding folder\n",
    "    --------------------------------\n",
    "    Input:\n",
    "        path (str): path where all classes folders are stored.\n",
    "        tags (list): list of classes names.\n",
    "    Output:\n",
    "        df (pd.DataFrame): pandas dataframe with the dataframes corresponding to all classes concatenated.\n",
    "    '''\n",
    "    list_of_dfs = []\n",
    "    for tag in tags:\n",
    "\n",
    "        df = create_df(path, tag)\n",
    "        list_of_dfs.append(df)\n",
    "    data = pd.concat(list_of_dfs)\n",
    "    return data\n",
    "\n",
    "\n",
    "def to_md5(rsc_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert rcs_id string into a hexdigest md5.\n",
    "    :param rcs_id: str.\n",
    "    :return: hexdigext representation of md5 codification of input string.\n",
    "    \"\"\"\n",
    "    md5_rsc = bytes(rsc_id, 'utf-8')\n",
    "    result_1 = md5(md5_rsc)\n",
    "    return result_1.hexdigest()\n",
    "\n",
    "\n",
    "def get_similarity(resources: pd.DataFrame, space: str = 'tfidf', max_df: float = .75) -> np.array:\n",
    "    \"\"\"\n",
    "    Compute pairwise cosine similarity for resources in a given vector representation (tf or tfidf).\n",
    "    :param resources: pd.DataFrame with the resources as rows and at least 'Text' as column.\n",
    "    :param space: vector space representation of resources, either 'tf' or 'tfidf'.\n",
    "    :param max_df: maximum valur for document frequency just as in sklearn Vectorizers.\n",
    "    :return: symmetric np.array with cosine similarity score for each resource pair.\n",
    "    \"\"\"\n",
    "    if space == 'tf':\n",
    "        vec = CountVectorizer(min_df=2, max_df=max_df)\n",
    "    elif space == 'tfidf':\n",
    "        vec = TfidfVectorizer(min_df=2, max_df=max_df)\n",
    "    else:\n",
    "        print('The \"space\" input must be either \"tf\" or \"tfidf\", using the default \"tfidf\" option...')\n",
    "        vec = TfidfVectorizer(min_df=2, max_df=max_df)\n",
    "    vec_res = vec.fit_transform(resources['Text'].fillna(''))\n",
    "    sims = cosine_similarity(vec_res, vec_res)\n",
    "    return sims\n",
    "\n",
    "\n",
    "def find_similar_rsc(similarity_scores: np.array, threshold: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get a dictionary relating resources to a list of [resource, score] pairs per resource.\n",
    "    :param similarity_scores: matrix of similarity score per pair of resources of shape\n",
    "    (number of resoures, number of resources).\n",
    "    :param threshold: the similarity score threshold for retrieving as similar resource.\n",
    "    :return: a pd.DataFrame with 'resource_idx', 'similar_res_idx' and 'similarity_score' as columns relating resources\n",
    "    to a given resource.\n",
    "    \"\"\"\n",
    "    similar_rsc_idx = np.where((similarity_scores >= threshold) & (similarity_scores < 0.999))\n",
    "    similar_scores = np.round(similarity_scores[similar_rsc_idx], 3)\n",
    "    sim_res = pd.DataFrame({'resource_idx': similar_rsc_idx[0],\n",
    "                            'similar_res_idx': similar_rsc_idx[1],\n",
    "                            'similarity_score': similar_scores})\n",
    "    return sim_res\n",
    "\n",
    "\n",
    "def get_similar_rsc(resources: pd.DataFrame, threshold: float = 0.75, space: str = 'tfidf') -> dict:\n",
    "    \"\"\"\n",
    "    Get similar resources per resource.\n",
    "    :param resources: pd.DataFrame with the resources as rows and at least 'Text' as column.\n",
    "    :param threshold: the similarity score threshold for retrieving as similar resource.\n",
    "    :param space: vector space representation of resources, either 'tf' or 'tfidf'.\n",
    "    :return: a dictionary with resources as keys and similar resources as values.\n",
    "    \"\"\"\n",
    "    sims = get_similarity(resources, space)\n",
    "    find_sims = find_similar_rsc(sims, threshold)\n",
    "    sim_df = find_sims.copy()\n",
    "    sim_df.reset_index(inplace=True)\n",
    "    sim_df['resource_id'] = resources['resource_id'].iloc[find_sims.resource_idx].values\n",
    "    sim_df['similar_res'] = resources['resource_id'].iloc[find_sims.similar_res_idx].values\n",
    "    sim_df['sim_resources'] = sim_df.apply(lambda x: [[x.similar_res, x.similarity_score]], axis=1)\n",
    "    grouped_sim_res = sim_df[['resource_id', 'sim_resources']].groupby('resource_id').agg(lambda x: np.sum(x))\n",
    "    similar_res_dict = grouped_sim_res.T.to_dict('records')[0]\n",
    "    sim_res = {k: sorted(v, key=lambda x: x[1], reverse=True) for k, v in similar_res_dict.items()}\n",
    "    return sim_res\n",
    "\n",
    "\n",
    "def get_similar(input_text: str, corpus: pd.DataFrame, threshold: float=0.75, space: str = 'tfidf') -> list:\n",
    "    \"\"\"\n",
    "    Retrieves a set of messages from a given corpus that are similar enough to an input message.\n",
    "    :param input_text: query text.\n",
    "    :param corpus: pd.DataFrame with historical messages as column 'Text'.\n",
    "    :param threshold: the similarity score threshold for retrieving as similar resource.\n",
    "    :param space: vector space representation of resources, either 'tf' or 'tfidf'.\n",
    "    :return: a list with all the similar messages content and corresponding score to the queried one.\n",
    "    \"\"\"\n",
    "    input_id = to_md5(input_text)\n",
    "    input_df = pd.DataFrame({'Text': [input_text], 'resource_id': [input_id]})\n",
    "    data = pd.concat([input_df, corpus])\n",
    "    sim_dict = get_similar_rsc(data, threshold, space)\n",
    "    result = list()\n",
    "    if sim_dict.get(input_id):\n",
    "        for sim_id, sim_score in sim_dict.get(input_id):\n",
    "            result.append([corpus['Text'][corpus['resource_id'] == sim_id].values[0], sim_score])\n",
    "    else:\n",
    "        result = [None, 0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparing data\n",
    "\n",
    "From a given set of messages, a historical corpus and a query message are defined. Thus, the query message is fed into the message matcher so that all messages from the corpus similar to the query one are retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../part1/dataset'\n",
    "tags = os.listdir(path)\n",
    "data_full = get_all_dfs(path, tags)[['Text']]\n",
    "data_full['resource_id'] = data_full['Text'].apply(to_md5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3467, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>resource_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104470</th>\n",
       "      <td>\\nDoes anyone know if the Twins games are broa...</td>\n",
       "      <td>fe1134865403a852cf05667ff01ba39c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104920</th>\n",
       "      <td>\\nIn article &lt;1993Apr16.163712.2466@VFL.Parama...</td>\n",
       "      <td>f823fc9041e5a9f8404350fe1297e9b0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102943</th>\n",
       "      <td>\\nIn article &lt;C5r43y.F0D@mentor.cc.purdue.edu&gt;...</td>\n",
       "      <td>fde34261174f65e47d336f65f0430f77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60158</th>\n",
       "      <td>\\nI am looking for a source of orbital element...</td>\n",
       "      <td>a6a481222792b03153858de37329e4a9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61049</th>\n",
       "      <td>\\n ETHER IMPLODES 2 EARTH CORE, IS GRAVITY!!!\\...</td>\n",
       "      <td>09e2677ec822057eed319ab763298a21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  \\\n",
       "file                                                        \n",
       "104470  \\nDoes anyone know if the Twins games are broa...   \n",
       "104920  \\nIn article <1993Apr16.163712.2466@VFL.Parama...   \n",
       "102943  \\nIn article <C5r43y.F0D@mentor.cc.purdue.edu>...   \n",
       "60158   \\nI am looking for a source of orbital element...   \n",
       "61049   \\n ETHER IMPLODES 2 EARTH CORE, IS GRAVITY!!!\\...   \n",
       "\n",
       "                             resource_id  \n",
       "file                                      \n",
       "104470  fe1134865403a852cf05667ff01ba39c  \n",
       "104920  f823fc9041e5a9f8404350fe1297e9b0  \n",
       "102943  fde34261174f65e47d336f65f0430f77  \n",
       "60158   a6a481222792b03153858de37329e4a9  \n",
       "61049   09e2677ec822057eed319ab763298a21  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = data_full.sample(int(data_full.shape[0] * 0.9))\n",
    "test_data = data_full[~data_full.resource_id.isin(corpus.resource_id)]\n",
    "print(corpus.shape)\n",
    "corpus.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Getting similar messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This appeared today in the \n",
      "\n",
      "The Japan Economic Journal reported GM plans to build a Toyota-badged car\n",
      "in the US for sale in Japan.  Bruce MacDonald, VP of GM Corporate\n",
      "Communications, yesterday confirmed that GM President and CEO Jack Smith\n",
      "had a meeting recently with Tatsuro Toyoda, President of Toyota.  \n",
      "this meeting the two discussed business opportunities to increase GM\n",
      "exports to Japan, including further component sales as well as completed\n",
      "vehicle sales,\n",
      "parts sales, the two presidents agreed conceptually to pursue an\n",
      "arrangement whereby GM would build a Toyota-badged, right-hand drive\n",
      "vehicle in the US for sale by Toyota in Japan.  A working group has been\n",
      "formed to finalize model specifications, exact timing and other details.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_text = test_data.iloc[42]['Text']\n",
    "print(query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar Messages:\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "The Chevrolet brothers were respected racers & test drivers for the\n",
      "Buick Co. when Durant was there.\n",
      "\n",
      "When the directors kicked Durant out of GM in 1910 he took Chevrolet and\n",
      "others with him.  As mentioned before, they founded the successful\n",
      "Chevrolet company.\n",
      "\n",
      "A little-known fact is that the Chevrolet Co. actually took over GM!\n",
      "That was how Durant got back in charge of GM-- legally his new company\n",
      "Chevrolet Co. did the buying, and GM was a division of Chevrolet!\n",
      "\n",
      "After 1920 and into the Sloan era, GM shuffled things so that the GM\n",
      "board was superior, but there was always a degree of autonomy given\n",
      "the Chevy division, presumably because of the initial structure.\n",
      "(If you look at the organization chart for GM in Sloan's book, Chevy\n",
      "division reports directly to 14th floor, not through the \"passenger\n",
      "car division\" which covers Buick, Olds, Cadillac, and Oakland/Pontiac)\n",
      "\n",
      "-Jeff Hagen    (minor deity of worthless auto-trivia)\n",
      " hagenjd@ac.wfu.edu\n",
      "\n",
      "Similarity score: 0.214\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "similar_results = get_similar(query_text, corpus, 0.2)\n",
    "if similar_results[0]:\n",
    "    print(\"Similar Messages:\")\n",
    "    for result in similar_results:\n",
    "        print(\"-\"*75)\n",
    "        print(result[0])\n",
    "        print(f\"Similarity score: {result[1]}\")\n",
    "        print(\"-\"*75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
